{
    "cells": [
        {
            "metadata": {},
            "cell_type": "code",
            "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.colors as cls\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.datasets import load_digits\n\ndataset = load_digits()\nX,y = dataset.data, dataset.target\nfor class_name, class_count in zip(dataset.target_names,np.bincount(dataset.target)):\n    print(class_name, class_count)\n# zip() \u51fd\u6570\u7528\u4e8e\u5c06\u53ef\u8fed\u4ee3\u7684\u5bf9\u8c61\u4f5c\u4e3a\u53c2\u6570\uff0c\u5c06\u5bf9\u8c61\u4e2d\u5bf9\u5e94\u7684\u5143\u7d20\u6253\u5305\u6210\u4e00\u4e2a\u4e2a\u5143\u7ec4\uff0c\u7136\u540e\u8fd4\u56de\u7531\u8fd9\u4e9b\u5143\u7ec4\u7ec4\u6210\u7684\u5217\u8868\u3002\n# \u5982\u679c\u5404\u4e2a\u8fed\u4ee3\u5668\u7684\u5143\u7d20\u4e2a\u6570\u4e0d\u4e00\u81f4\uff0c\u5219\u8fd4\u56de\u5217\u8868\u957f\u5ea6\u4e0e\u6700\u77ed\u7684\u5bf9\u8c61\u76f8\u540c\uff0c\u5229\u7528 * \u53f7\u64cd\u4f5c\u7b26\uff0c\u53ef\u4ee5\u5c06\u5143\u7ec4\u89e3\u538b\u4e3a\u5217\u8868\u3002\n# np.bincount() Count number of occurrences of each value in array of non-negative ints.\n# \u663e\u7136\u662f\u8fd9\u91cc\u4ece0\u5f00\u59cb\u8ba1\u7b97\u51fa\u73b0\u6b21\u6570\u7684\uff0c\u6240\u4ee5\u6700\u540e\u4e00\u4e2a\u662f\u6700\u5927\u503c: 0\u51fa\u73b0\u51e0\u6b21\uff0c1\u51fa\u73b0\u51e0\u6b21\uff0c\u4e00\u76f4\u52309\u51fa\u73b0\u51e0\u6b21",
            "execution_count": 2,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "0 178\n1 182\n2 177\n3 183\n4 181\n5 182\n6 181\n7 179\n8 174\n9 180\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "y_binary_imbalanced = y.copy()\ny_binary_imbalanced[y_binary_imbalanced !=1] = 0\nprint('Orinal labels:    ',y[:30])\nprint('New binary labels:',y_binary_imbalanced[:30])",
            "execution_count": 3,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Orinal labels:     [0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9]\nNew binary labels: [0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "np.bincount(y_binary_imbalanced)",
            "execution_count": 4,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 4,
                    "data": {
                        "text/plain": "array([1615,  182])"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from sklearn.svm import SVC\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y_binary_imbalanced,random_state=0)\nsvm = SVC(kernel='rbf',C=1).fit(X_train,y_train)\nsvm.score(X_test,y_test)",
            "execution_count": 5,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n  \"avoid this warning.\", FutureWarning)\n",
                    "name": "stderr"
                },
                {
                    "output_type": "execute_result",
                    "execution_count": 5,
                    "data": {
                        "text/plain": "0.9088888888888889"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Dummy Classifiers"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from sklearn.dummy import DummyClassifier\ndummy_majority = DummyClassifier(strategy='most_frequent').fit(X_train,y_train)\ny_dummy_predictions = dummy_majority.predict(X_test)\ny_dummy_predictions\n# most_frequent: \u9884\u6d4b\u503c\u662f\u51fa\u73b0\u9891\u7387\u6700\u9ad8\u7684\u7c7b\u522b\ndummy_majority.score(X_test,y_test)",
            "execution_count": 6,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 6,
                    "data": {
                        "text/plain": "0.9044444444444445"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "svm = SVC(kernel='linear',C=1).fit(X_train,y_train)\nsvm.score(X_test,y_test)",
            "execution_count": 7,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 7,
                    "data": {
                        "text/plain": "0.9777777777777777"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## confusion matrix"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### binary confusion marix"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from sklearn.metrics import confusion_matrix\ndummy_majority = DummyClassifier(strategy='most_frequent').fit(X_train,y_train)\ny_dummy_predictions = dummy_majority.predict(X_test)\nconfusion = confusion_matrix(y_test,y_dummy_predictions)\nprint('most frequent class (dummy classifier)\\n',confusion)",
            "execution_count": 8,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "most frequent class (dummy classifier)\n [[407   0]\n [ 43   0]]\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "dummy_classprop = DummyClassifier(strategy='stratified').fit(X_train,y_train)\ny_classprop_predicted = dummy_classprop.predict(X_test)\nconfusion = confusion_matrix(y_test,y_classprop_predicted)\nprint('random class-proportional prediction (dummy classifier)\\n',confusion)",
            "execution_count": 9,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "random class-proportional prediction (dummy classifier)\n [[360  47]\n [ 40   3]]\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "svm = SVC(kernel='linear',C=1).fit(X_train,y_train)\nsvm_predicted = svm.predict(X_test)\nconfusion = confusion_matrix(y_test,svm_predicted)\nprint('SVM classifier (linear kernal, C=1)\\n',confusion)",
            "execution_count": 10,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "SVM classifier (linear kernal, C=1)\n [[402   5]\n [  5  38]]\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from sklearn.linear_model import LogisticRegression\nlr = LogisticRegression().fit(X_train,y_train)\nlr_predicted = lr.predict(X_test)\nconfusion = confusion_matrix(y_test,lr_predicted)\nprint('logistic regression (defalt settings)\\n',confusion)",
            "execution_count": 11,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n",
                    "name": "stderr"
                },
                {
                    "output_type": "stream",
                    "text": "logistic regression (defalt settings)\n [[401   6]\n [  6  37]]\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from sklearn.tree import DecisionTreeClassifier\ndt = DecisionTreeClassifier(max_depth=2).fit(X_train,y_train)\ntree_predicted = dt.predict(X_test)\nconfusion = confusion_matrix(y_test,tree_predicted)\nprint('Decision Tree Classifier(max_depth=2)\\n',confusion)",
            "execution_count": 12,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Decision Tree Classifier(max_depth=2)\n [[400   7]\n [ 17  26]]\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Evaluation metrics for binary classification"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\nprint('Accuracy: {:.2f}'.format(accuracy_score(y_test,tree_predicted)))\nprint('Precision: {:.2f}'.format(precision_score(y_test,tree_predicted)))\nprint('Recall: {:.2f}'.format(recall_score(y_test,tree_predicted)))\nprint('F1: {:.2f}'.format(f1_score(y_test,tree_predicted)))",
            "execution_count": 14,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Accuracy: 0.95\nPrecision: 0.79\nRecall: 0.60\nF1: 0.68\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from sklearn.metrics import classification_report\nprint(classification_report(y_test,tree_predicted,target_names=['not 1','1']))\n# support \u662f\u6d4b\u8bd5\u96c6\u4e2d\u6807\u7b7e\u4e3atrue\u7684\u6570\u91cf",
            "execution_count": 16,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "              precision    recall  f1-score   support\n\n       not 1       0.96      0.98      0.97       407\n           1       0.79      0.60      0.68        43\n\n   micro avg       0.95      0.95      0.95       450\n   macro avg       0.87      0.79      0.83       450\nweighted avg       0.94      0.95      0.94       450\n\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "print('Random class-proportional (dummy)\\n',\n      classification_report(y_test,y_classprop_predicted,target_names=['not 1','1']))\nprint('SVM\\n',\n      classification_report(y_test,svm_predicted,target_names=['not 1','1']))\nprint('Logistic regression\\n',\n      classification_report(y_test,lr_predicted,target_names=['not 1','1']))\nprint('Decision tree\\n',\n      classification_report(y_test,tree_predicted,target_names=['not 1','1']))",
            "execution_count": 17,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Random class-proportional (dummy)\n               precision    recall  f1-score   support\n\n       not 1       0.90      0.88      0.89       407\n           1       0.06      0.07      0.06        43\n\n   micro avg       0.81      0.81      0.81       450\n   macro avg       0.48      0.48      0.48       450\nweighted avg       0.82      0.81      0.81       450\n\nSVM\n               precision    recall  f1-score   support\n\n       not 1       0.99      0.99      0.99       407\n           1       0.88      0.88      0.88        43\n\n   micro avg       0.98      0.98      0.98       450\n   macro avg       0.94      0.94      0.94       450\nweighted avg       0.98      0.98      0.98       450\n\nLogistic regression\n               precision    recall  f1-score   support\n\n       not 1       0.99      0.99      0.99       407\n           1       0.86      0.86      0.86        43\n\n   micro avg       0.97      0.97      0.97       450\n   macro avg       0.92      0.92      0.92       450\nweighted avg       0.97      0.97      0.97       450\n\nDecision tree\n               precision    recall  f1-score   support\n\n       not 1       0.96      0.98      0.97       407\n           1       0.79      0.60      0.68        43\n\n   micro avg       0.95      0.95      0.95       450\n   macro avg       0.87      0.79      0.83       450\nweighted avg       0.94      0.95      0.94       450\n\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Decison functions"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "X_train,X_test,y_train,y_test = train_test_split(X,y_binary_imbalanced,random_state=0)\ny_scores_lr = lr.fit(X_train,y_train).decision_function(X_test)\ny_score_list = list(zip(y_test[0:20],y_scores_lr[0:20]))\ny_score_list",
            "execution_count": 18,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n",
                    "name": "stderr"
                },
                {
                    "output_type": "execute_result",
                    "execution_count": 18,
                    "data": {
                        "text/plain": "[(0, -23.17711236290324),\n (0, -13.541470729541413),\n (0, -21.72290098969473),\n (0, -18.907438437430027),\n (0, -19.73582172900229),\n (0, -9.749807819560061),\n (1, 5.2349604859009276),\n (0, -19.307551661127864),\n (0, -25.101182889530396),\n (0, -21.82736239135058),\n (0, -24.151343401889438),\n (0, -19.576969790071697),\n (0, -22.574689400560423),\n (0, -10.823324268750714),\n (0, -11.912123406737392),\n (0, -10.97922371337485),\n (1, 11.206006114721543),\n (0, -27.64600231793191),\n (0, -12.859381428186682),\n (0, -25.848764845244997)]"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Multi-Class Evaluation"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "dataset = load_digits()\nX,y = dataset.data,dataset.target\nX_train_mc,X_test_mc,y_train_mc,y_test_mc = train_test_split(X,y,random_state=0)\nsvm = SVC(kernel='linear').fit(X_train_mc,y_train_mc)\nsvm_predicted_mc = svm.predict(X_test_mc)",
            "execution_count": 23,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.6",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.6.8",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}